{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db43153",
   "metadata": {},
   "source": [
    "# Premier League Betting App – Match Outcome & Score Prediction\n",
    "\n",
    "This notebook implements the pipeline described in the project proposal:\n",
    "\n",
    "- **Client:** Premier League Betting App  \n",
    "- **Goal:**  \n",
    "  - Classification: Predict the **match outcome**  \n",
    "    - `0` = Home Win, `1` = Away Win, `2` = Draw  \n",
    "  - Regression: Predict the **final score** (home & away goals).  \n",
    "- **Data:** Premier League matchup stats (e.g., Kaggle datasets for seasons 2019/2020, 2020/2021, 2021/2022) concatenated into a single dataset.  \n",
    "- **Models:**  \n",
    "  - **Classification:** SVM, Random Forest, Logistic Regression  \n",
    "  - **Regression:** Linear Regression (with regularization), Random Forest Regressor, Gradient Boosting Regressor  \n",
    "- **Framework:** Preprocessing → Data splitting → Hyperparameter tuning → Model training → Validation → Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fd9771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing & model selection\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Classification models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Regression models\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    mean_squared_error, r2_score\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca349100",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "Update the file paths below to point to your downloaded Kaggle CSV files for the **Premier League** seasons\n",
    "2019/2020, 2020/2021, and 2021/2022.\n",
    "\n",
    "You may have columns like:\n",
    "\n",
    "- `HomeTeam`, `AwayTeam`\n",
    "- `FTHG` (Full-Time Home Goals), `FTAG` (Full-Time Away Goals)\n",
    "- `FTR` (Full-Time Result) as `'H'`, `'A'`, `'D'`\n",
    "\n",
    "You can adjust the column names in the preprocessing steps later if your dataset uses different ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "373f28a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020, 106)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>Referee</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>BWH</th>\n",
       "      <th>BWD</th>\n",
       "      <th>BWA</th>\n",
       "      <th>IWH</th>\n",
       "      <th>IWD</th>\n",
       "      <th>IWA</th>\n",
       "      <th>PSH</th>\n",
       "      <th>PSD</th>\n",
       "      <th>PSA</th>\n",
       "      <th>WHH</th>\n",
       "      <th>WHD</th>\n",
       "      <th>WHA</th>\n",
       "      <th>VCH</th>\n",
       "      <th>VCD</th>\n",
       "      <th>VCA</th>\n",
       "      <th>MaxH</th>\n",
       "      <th>MaxD</th>\n",
       "      <th>MaxA</th>\n",
       "      <th>AvgH</th>\n",
       "      <th>AvgD</th>\n",
       "      <th>AvgA</th>\n",
       "      <th>B365&gt;2.5</th>\n",
       "      <th>B365&lt;2.5</th>\n",
       "      <th>...</th>\n",
       "      <th>AHh</th>\n",
       "      <th>B365AHH</th>\n",
       "      <th>B365AHA</th>\n",
       "      <th>PAHH</th>\n",
       "      <th>PAHA</th>\n",
       "      <th>MaxAHH</th>\n",
       "      <th>MaxAHA</th>\n",
       "      <th>AvgAHH</th>\n",
       "      <th>AvgAHA</th>\n",
       "      <th>B365CH</th>\n",
       "      <th>B365CD</th>\n",
       "      <th>B365CA</th>\n",
       "      <th>BWCH</th>\n",
       "      <th>BWCD</th>\n",
       "      <th>BWCA</th>\n",
       "      <th>IWCH</th>\n",
       "      <th>IWCD</th>\n",
       "      <th>IWCA</th>\n",
       "      <th>PSCH</th>\n",
       "      <th>PSCD</th>\n",
       "      <th>PSCA</th>\n",
       "      <th>WHCH</th>\n",
       "      <th>WHCD</th>\n",
       "      <th>WHCA</th>\n",
       "      <th>VCCH</th>\n",
       "      <th>VCCD</th>\n",
       "      <th>VCCA</th>\n",
       "      <th>MaxCH</th>\n",
       "      <th>MaxCD</th>\n",
       "      <th>MaxCA</th>\n",
       "      <th>AvgCH</th>\n",
       "      <th>AvgCD</th>\n",
       "      <th>AvgCA</th>\n",
       "      <th>B365C&gt;2.5</th>\n",
       "      <th>B365C&lt;2.5</th>\n",
       "      <th>PC&gt;2.5</th>\n",
       "      <th>PC&lt;2.5</th>\n",
       "      <th>MaxC&gt;2.5</th>\n",
       "      <th>MaxC&lt;2.5</th>\n",
       "      <th>AvgC&gt;2.5</th>\n",
       "      <th>AvgC&lt;2.5</th>\n",
       "      <th>AHCh</th>\n",
       "      <th>B365CAHH</th>\n",
       "      <th>B365CAHA</th>\n",
       "      <th>PCAHH</th>\n",
       "      <th>PCAHA</th>\n",
       "      <th>MaxCAHH</th>\n",
       "      <th>MaxCAHA</th>\n",
       "      <th>AvgCAHH</th>\n",
       "      <th>AvgCAHA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E0</td>\n",
       "      <td>09/08/2019</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>M Oliver</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>10.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>8.25</td>\n",
       "      <td>18.50</td>\n",
       "      <td>1.15</td>\n",
       "      <td>8.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>1.15</td>\n",
       "      <td>9.59</td>\n",
       "      <td>18.05</td>\n",
       "      <td>1.12</td>\n",
       "      <td>8.5</td>\n",
       "      <td>21.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>9.5</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1.16</td>\n",
       "      <td>10.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>8.75</td>\n",
       "      <td>19.83</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.14</td>\n",
       "      <td>9.50</td>\n",
       "      <td>21.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1.15</td>\n",
       "      <td>8.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>10.43</td>\n",
       "      <td>19.63</td>\n",
       "      <td>1.11</td>\n",
       "      <td>9.5</td>\n",
       "      <td>21.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>9.50</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1.16</td>\n",
       "      <td>10.50</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>9.52</td>\n",
       "      <td>19.18</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.34</td>\n",
       "      <td>3.44</td>\n",
       "      <td>1.36</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.32</td>\n",
       "      <td>3.43</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0</td>\n",
       "      <td>10/08/2019</td>\n",
       "      <td>12:30</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>Man City</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>M Dean</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1.22</td>\n",
       "      <td>11.50</td>\n",
       "      <td>5.75</td>\n",
       "      <td>1.26</td>\n",
       "      <td>11.00</td>\n",
       "      <td>6.10</td>\n",
       "      <td>1.25</td>\n",
       "      <td>11.68</td>\n",
       "      <td>6.53</td>\n",
       "      <td>1.26</td>\n",
       "      <td>13.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.24</td>\n",
       "      <td>12.00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.25</td>\n",
       "      <td>13.00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.29</td>\n",
       "      <td>11.84</td>\n",
       "      <td>6.28</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2.75</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.89</td>\n",
       "      <td>12.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>11.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>11.00</td>\n",
       "      <td>6.10</td>\n",
       "      <td>1.25</td>\n",
       "      <td>11.11</td>\n",
       "      <td>6.68</td>\n",
       "      <td>1.27</td>\n",
       "      <td>11.00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.24</td>\n",
       "      <td>12.00</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1.25</td>\n",
       "      <td>13.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.29</td>\n",
       "      <td>11.14</td>\n",
       "      <td>6.46</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.43</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1.50</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1.41</td>\n",
       "      <td>2.91</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E0</td>\n",
       "      <td>10/08/2019</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Sheffield United</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>K Friend</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.97</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.04</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.06</td>\n",
       "      <td>3.65</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.01</td>\n",
       "      <td>3.53</td>\n",
       "      <td>3.83</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.90</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.89</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.70</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.97</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1.98</td>\n",
       "      <td>3.67</td>\n",
       "      <td>4.06</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>3.70</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.98</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.96</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.92</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E0</td>\n",
       "      <td>10/08/2019</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>G Scott</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.62</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.71</td>\n",
       "      <td>3.31</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.72</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.98</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.71</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.72</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.18</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.89</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E0</td>\n",
       "      <td>10/08/2019</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Everton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>J Moss</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.37</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.39</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.45</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.52</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2.04</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.27</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.34</td>\n",
       "      <td>3.41</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.23</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.74</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.96</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Div        Date   Time        HomeTeam          AwayTeam  FTHG  FTAG FTR  \\\n",
       "0  E0  09/08/2019  20:00       Liverpool           Norwich     4     1   H   \n",
       "1  E0  10/08/2019  12:30        West Ham          Man City     0     5   A   \n",
       "2  E0  10/08/2019  15:00     Bournemouth  Sheffield United     1     1   D   \n",
       "3  E0  10/08/2019  15:00         Burnley       Southampton     3     0   H   \n",
       "4  E0  10/08/2019  15:00  Crystal Palace           Everton     0     0   D   \n",
       "\n",
       "   HTHG  HTAG HTR   Referee  HS  AS  HST  AST  HF  AF  HC  AC  HY  AY  HR  AR  \\\n",
       "0     4     0   H  M Oliver  15  12    7    5   9   9  11   2   0   2   0   0   \n",
       "1     0     1   A    M Dean   5  14    3    9   6  13   1   1   2   2   0   0   \n",
       "2     0     0   D  K Friend  13   8    3    3  10  19   3   4   2   1   0   0   \n",
       "3     0     0   D   G Scott  10  11    4    3   6  12   2   7   0   0   0   0   \n",
       "4     0     0   D    J Moss   6  10    2    3  16  14   6   2   2   1   0   1   \n",
       "\n",
       "   B365H  B365D  B365A    BWH   BWD    BWA    IWH   IWD    IWA    PSH   PSD  \\\n",
       "0   1.14  10.00  19.00   1.14  8.25  18.50   1.15  8.00  18.00   1.15  9.59   \n",
       "1  12.00   6.50   1.22  11.50  5.75   1.26  11.00  6.10   1.25  11.68  6.53   \n",
       "2   1.95   3.60   3.60   1.95  3.60   3.90   1.97  3.55   3.80   2.04  3.57   \n",
       "3   2.62   3.20   2.75   2.65  3.20   2.75   2.65  3.20   2.75   2.71  3.31   \n",
       "4   3.00   3.25   2.37   3.20  3.20   2.35   3.10  3.20   2.40   3.21  3.37   \n",
       "\n",
       "     PSA    WHH  WHD    WHA    VCH  VCD    VCA   MaxH   MaxD   MaxA   AvgH  \\\n",
       "0  18.05   1.12  8.5  21.00   1.14  9.5  23.00   1.16  10.00  23.00   1.14   \n",
       "1   1.26  13.00  6.0   1.24  12.00  6.5   1.25  13.00   6.75   1.29  11.84   \n",
       "2   3.90   2.00  3.5   3.80   2.00  3.6   4.00   2.06   3.65   4.00   2.01   \n",
       "3   2.81   2.70  3.2   2.75   2.70  3.3   2.80   2.80   3.33   2.85   2.68   \n",
       "4   2.39   3.10  3.3   2.35   3.20  3.3   2.45   3.21   3.40   2.52   3.13   \n",
       "\n",
       "   AvgD   AvgA  B365>2.5  B365<2.5  ...   AHh  B365AHH  B365AHA  PAHH  PAHA  \\\n",
       "0  8.75  19.83      1.40      3.00  ... -2.25     1.96     1.94  1.97  1.95   \n",
       "1  6.28   1.25      1.44      2.75  ...  1.75     2.00     1.90  2.02  1.90   \n",
       "2  3.53   3.83      1.90      1.90  ... -0.50     2.01     1.89  2.04  1.88   \n",
       "3  3.22   2.78      2.10      1.72  ...  0.00     1.92     1.98  1.93  2.00   \n",
       "4  3.27   2.40      2.20      1.66  ...  0.25     1.85     2.05  1.88  2.05   \n",
       "\n",
       "   MaxAHH  MaxAHA  AvgAHH  AvgAHA  B365CH  B365CD  B365CA   BWCH  BWCD   BWCA  \\\n",
       "0    1.97    2.00    1.94    1.94    1.14    9.50   21.00   1.14   9.0  20.00   \n",
       "1    2.02    1.92    1.99    1.89   12.00    7.00    1.25  11.00   6.0   1.26   \n",
       "2    2.04    1.91    2.00    1.88    1.95    3.70    4.20   1.95   3.6   3.90   \n",
       "3    1.94    2.00    1.91    1.98    2.70    3.25    2.90   2.65   3.1   2.85   \n",
       "4    1.88    2.09    1.84    2.04    3.40    3.50    2.25   3.30   3.3   2.25   \n",
       "\n",
       "    IWCH  IWCD   IWCA   PSCH   PSCD   PSCA   WHCH  WHCD   WHCA   VCCH  VCCD  \\\n",
       "0   1.15  8.00  18.00   1.14  10.43  19.63   1.11   9.5  21.00   1.14  9.50   \n",
       "1  11.00  6.10   1.25  11.11   6.68   1.27  11.00   6.5   1.24  12.00  6.50   \n",
       "2   1.97  3.55   3.85   1.98   3.67   4.06   1.95   3.6   3.90   2.00  3.60   \n",
       "3   2.60  3.20   2.85   2.71   3.19   2.90   2.62   3.2   2.80   2.70  3.25   \n",
       "4   3.40  3.30   2.20   3.37   3.45   2.27   3.30   3.3   2.25   3.40  3.30   \n",
       "\n",
       "    VCCA  MaxCH  MaxCD  MaxCA  AvgCH  AvgCD  AvgCA  B365C>2.5  B365C<2.5  \\\n",
       "0  23.00   1.16  10.50  23.00   1.14   9.52  19.18        1.3       3.50   \n",
       "1   1.25  13.00   7.00   1.29  11.14   6.46   1.26        1.4       3.00   \n",
       "2   4.00   2.03   3.70   4.20   1.98   3.58   3.96        1.9       1.90   \n",
       "3   2.90   2.72   3.26   2.95   2.65   3.18   2.88        2.1       1.72   \n",
       "4   2.25   3.55   3.50   2.34   3.41   3.37   2.23        2.2       1.66   \n",
       "\n",
       "   PC>2.5  PC<2.5  MaxC>2.5  MaxC<2.5  AvgC>2.5  AvgC<2.5  AHCh  B365CAHH  \\\n",
       "0    1.34    3.44      1.36      3.76      1.32      3.43 -2.25      1.91   \n",
       "1    1.43    3.03      1.50      3.22      1.41      2.91  1.75      1.95   \n",
       "2    1.94    1.97      1.97      1.98      1.91      1.92 -0.50      1.95   \n",
       "3    2.19    1.76      2.25      1.78      2.17      1.71  0.00      1.87   \n",
       "4    2.22    1.74      2.28      1.77      2.17      1.71  0.25      1.82   \n",
       "\n",
       "   B365CAHA  PCAHH  PCAHA  MaxCAHH  MaxCAHA  AvgCAHH  AvgCAHA  \n",
       "0      1.99   1.94   1.98     1.99     2.07     1.90     1.99  \n",
       "1      1.95   1.96   1.97     2.07     1.98     1.97     1.92  \n",
       "2      1.95   1.98   1.95     2.00     1.96     1.96     1.92  \n",
       "3      2.03   1.89   2.03     1.90     2.07     1.86     2.02  \n",
       "4      2.08   1.97   1.96     2.03     2.08     1.96     1.93  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Update these paths to match your local dataset files\n",
    "path_2019_2020 = \"2019-20.csv\"\n",
    "path_2020_2021 = \"2020-2021.csv\"\n",
    "path_2021_2022 = \"2021-2022.csv\"\n",
    "\n",
    "# Load datasets\n",
    "df_19_20 = pd.read_csv(path_2019_2020)\n",
    "df_20_21 = pd.read_csv(path_2020_2021)\n",
    "df_21_22 = pd.read_csv(path_2021_2022)\n",
    "\n",
    "# Concatenate datasets\n",
    "df = pd.concat([df_19_20, df_20_21, df_21_22], ignore_index=True)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78a29b8",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Quick sanity checks: data types, missing values, and simple distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6339d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of the dataset\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47d8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check basic statistics for numerical columns\n",
    "df.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0028f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "df.isna().mean().sort_values(ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b553a2e6",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering & Target Definition\n",
    "\n",
    "We define:\n",
    "\n",
    "- **Classification target `y_cls`**: Match outcome encoded as  \n",
    "  - `0` = Home Win  \n",
    "  - `1` = Away Win  \n",
    "  - `2` = Draw  \n",
    "\n",
    "- **Regression targets `y_reg_home` and `y_reg_away`**: Final scores (home & away goals).\n",
    "\n",
    "Adjust the column names in this section if your dataset uses different labels for goals and result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5a28cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Adjust these column names to match your dataset ----\n",
    "home_team_col = \"HomeTeam\"\n",
    "away_team_col = \"AwayTeam\"\n",
    "home_goals_col = \"FTHG\"  # Full Time Home Goals\n",
    "away_goals_col = \"FTAG\"  # Full Time Away Goals\n",
    "result_col = \"FTR\"       # Full Time Result: 'H', 'A', 'D'\n",
    "\n",
    "# Map textual result to numeric class: 0=Home Win, 1=Away Win, 2=Draw\n",
    "result_mapping = {\"H\": 0, \"A\": 1, \"D\": 2}\n",
    "df = df.dropna(subset=[home_goals_col, away_goals_col, result_col])\n",
    "df[\"match_outcome\"] = df[result_col].map(result_mapping)\n",
    "\n",
    "# Regression targets\n",
    "df[\"home_score\"] = df[home_goals_col]\n",
    "df[\"away_score\"] = df[away_goals_col]\n",
    "\n",
    "# Example feature set: you can expand this with more stats from your dataset\n",
    "# For now, let's include team names + any other numeric stats that might exist.\n",
    "feature_cols_categorical = [home_team_col, away_team_col]\n",
    "feature_cols_numeric = [\n",
    "    col for col in df.columns\n",
    "    if col not in feature_cols_categorical\n",
    "    and col not in [home_goals_col, away_goals_col, result_col, \"match_outcome\", \"home_score\", \"away_score\"]\n",
    "    and pd.api.types.is_numeric_dtype(df[col])\n",
    "]\n",
    "\n",
    "print(\"Categorical features:\", feature_cols_categorical)\n",
    "print(\"Numeric features:\", feature_cols_numeric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abda781c",
   "metadata": {},
   "source": [
    "## 4. Train–Test Split\n",
    "\n",
    "We split the data into:\n",
    "\n",
    "- **Training set:** 80%  \n",
    "- **Test set:** 20%  \n",
    "\n",
    "We will perform **5-fold cross-validation** on the training set during hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4f55bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle to reduce temporal bias if data is ordered by date\n",
    "df = shuffle(df, random_state=42).reset_index(drop=True)\n",
    "\n",
    "X = df[feature_cols_categorical + feature_cols_numeric]\n",
    "\n",
    "# Classification target\n",
    "y_cls = df[\"match_outcome\"]\n",
    "\n",
    "# Regression targets\n",
    "y_reg_home = df[\"home_score\"]\n",
    "y_reg_away = df[\"away_score\"]\n",
    "\n",
    "X_train, X_test, y_cls_train, y_cls_test, y_reg_home_train, y_reg_home_test, y_reg_away_train, y_reg_away_test = train_test_split(\n",
    "    X, y_cls, y_reg_home, y_reg_away, test_size=0.2, random_state=42, stratify=y_cls\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba63fc9d",
   "metadata": {},
   "source": [
    "## 5. Preprocessing Pipelines\n",
    "\n",
    "We apply the following preprocessing steps:\n",
    "\n",
    "- **Missing values:** `SimpleImputer` with mean (numeric) or most frequent (categorical)  \n",
    "- **Scaling:** `StandardScaler` for numeric features  \n",
    "- **Encoding:** `OneHotEncoder` for categorical features  \n",
    "\n",
    "We build a `ColumnTransformer` to apply the correct preprocessing to each subset of columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3684ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric preprocessing: impute missing values with mean, then scale\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Categorical preprocessing: impute most frequent, then one-hot encode\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Combined preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, feature_cols_numeric),\n",
    "        (\"cat\", categorical_transformer, feature_cols_categorical),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f260f7c0",
   "metadata": {},
   "source": [
    "## 6. Classification – Match Outcome\n",
    "\n",
    "We train and tune:\n",
    "\n",
    "- **SVM (SVC)** – tuning `kernel`, `C`, `gamma`  \n",
    "- **RandomForestClassifier** – tuning `n_estimators`, `max_depth`, `min_samples_split`  \n",
    "- **LogisticRegression** – tuning `penalty` (L1/L2) and `C`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3822ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_results = {}\n",
    "\n",
    "# Helper function to run GridSearchCV and store results\n",
    "def run_classification_grid_search(model, param_grid, model_name):\n",
    "    pipe = Pipeline(steps=[(\"preprocess\", preprocessor), (\"model\", model)])\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        pipe,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "    )\n",
    "    grid.fit(X_train, y_cls_train)\n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_cls_test, y_pred)\n",
    "    prec = precision_score(y_cls_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    rec = recall_score(y_cls_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(y_cls_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    \n",
    "    classification_results[model_name] = {\n",
    "        \"best_params\": grid.best_params_,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "        \"best_model\": best_model,\n",
    "        \"y_pred\": y_pred,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(\"Best params:\", grid.best_params_)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision (weighted): {prec:.4f}\")\n",
    "    print(f\"Recall (weighted): {rec:.4f}\")\n",
    "    print(f\"F1-score (weighted): {f1:.4f}\")\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_cls_test, y_pred, zero_division=0))\n",
    "    \n",
    "    return best_model, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146e34a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 SVM (SVC)\n",
    "svm_param_grid = {\n",
    "    \"model__kernel\": [\"rbf\", \"linear\"],\n",
    "    \"model__C\": [0.1, 1, 10],\n",
    "    \"model__gamma\": [\"scale\", \"auto\"],\n",
    "}\n",
    "\n",
    "svm_model, svm_y_pred = run_classification_grid_search(\n",
    "    SVC(probability=True),\n",
    "    svm_param_grid,\n",
    "    model_name=\"SVM\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b29880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 Random Forest Classifier\n",
    "rf_cls_param_grid = {\n",
    "    \"model__n_estimators\": [100, 200],\n",
    "    \"model__max_depth\": [None, 10, 20],\n",
    "    \"model__min_samples_split\": [2, 5],\n",
    "}\n",
    "\n",
    "rf_cls_model, rf_cls_y_pred = run_classification_grid_search(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    rf_cls_param_grid,\n",
    "    model_name=\"RandomForestClassifier\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181dca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 Logistic Regression\n",
    "log_reg_param_grid = {\n",
    "    \"model__penalty\": [\"l1\", \"l2\"],\n",
    "    \"model__C\": [0.1, 1, 10],\n",
    "    \"model__solver\": [\"liblinear\"],  # supports L1 and L2\n",
    "}\n",
    "\n",
    "log_reg_model, log_reg_y_pred = run_classification_grid_search(\n",
    "    LogisticRegression(max_iter=1000, multi_class=\"auto\"),\n",
    "    log_reg_param_grid,\n",
    "    model_name=\"LogisticRegression\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39265efe",
   "metadata": {},
   "source": [
    "### 6.4 Confusion Matrices & Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2696319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_for_model(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    im = ax.imshow(cm, interpolation=\"nearest\")\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(\n",
    "        xticks=range(3),\n",
    "        yticks=range(3),\n",
    "        xticklabels=[\"Home Win (0)\", \"Away Win (1)\", \"Draw (2)\"],\n",
    "        yticklabels=[\"Home Win (0)\", \"Away Win (1)\", \"Draw (2)\"],\n",
    "        ylabel=\"True label\",\n",
    "        xlabel=\"Predicted label\",\n",
    "        title=title,\n",
    "    )\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    \n",
    "    # Annotate\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(\n",
    "                j, i, format(cm[i, j], \"d\"),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\"\n",
    "            )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for name, res in classification_results.items():\n",
    "    plot_confusion_matrix_for_model(y_cls_test, res[\"y_pred\"], f\"Confusion Matrix – {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197b6475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare classification models by metrics\n",
    "cls_summary = pd.DataFrame(\n",
    "    {\n",
    "        name: {\n",
    "            \"accuracy\": res[\"accuracy\"],\n",
    "            \"precision_weighted\": res[\"precision\"],\n",
    "            \"recall_weighted\": res[\"recall\"],\n",
    "            \"f1_weighted\": res[\"f1\"],\n",
    "        }\n",
    "        for name, res in classification_results.items()\n",
    "    }\n",
    ").T\n",
    "\n",
    "cls_summary.sort_values(\"accuracy\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07efc838",
   "metadata": {},
   "source": [
    "## 7. Regression – Final Scores\n",
    "\n",
    "We train and tune:\n",
    "\n",
    "- **Linear Regression with regularization**: Ridge (L2) and Lasso (L1)  \n",
    "- **RandomForestRegressor** – tuning `n_estimators`, `max_depth`  \n",
    "- **GradientBoostingRegressor** – tuning `n_estimators`, `max_depth`, `learning_rate`  \n",
    "\n",
    "We build **separate models** for home and away scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d0c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results_home = {}\n",
    "regression_results_away = {}\n",
    "\n",
    "def run_regression_grid_search(base_model, param_grid, model_name, y_train, y_test, target_label, results_dict):\n",
    "    pipe = Pipeline(steps=[(\"preprocess\", preprocessor), (\"model\", base_model)])\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        pipe,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results_dict[model_name] = {\n",
    "        \"best_params\": grid.best_params_,\n",
    "        \"rmse\": rmse,\n",
    "        \"r2\": r2,\n",
    "        \"best_model\": best_model,\n",
    "        \"y_pred\": y_pred,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n[{target_label}] Model: {model_name}\")\n",
    "    print(\"Best params:\", grid.best_params_)\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R^2: {r2:.4f}\")\n",
    "    \n",
    "    return best_model, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e8ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Ridge Regression – Home score\n",
    "ridge_param_grid = {\n",
    "    \"model__alpha\": [0.1, 1.0, 10.0],\n",
    "}\n",
    "\n",
    "ridge_home_model, ridge_home_pred = run_regression_grid_search(\n",
    "    Ridge(),\n",
    "    ridge_param_grid,\n",
    "    model_name=\"Ridge\",\n",
    "    y_train=y_reg_home_train,\n",
    "    y_test=y_reg_home_test,\n",
    "    target_label=\"Home Score\",\n",
    "    results_dict=regression_results_home,\n",
    ")\n",
    "\n",
    "# 7.2 Lasso Regression – Home score\n",
    "lasso_param_grid = {\n",
    "    \"model__alpha\": [0.001, 0.01, 0.1, 1.0],\n",
    "}\n",
    "\n",
    "lasso_home_model, lasso_home_pred = run_regression_grid_search(\n",
    "    Lasso(max_iter=10000),\n",
    "    lasso_param_grid,\n",
    "    model_name=\"Lasso\",\n",
    "    y_train=y_reg_home_train,\n",
    "    y_test=y_reg_home_test,\n",
    "    target_label=\"Home Score\",\n",
    "    results_dict=regression_results_home,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ed8a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3 RandomForestRegressor – Home score\n",
    "rf_reg_param_grid = {\n",
    "    \"model__n_estimators\": [100, 200],\n",
    "    \"model__max_depth\": [None, 10, 20],\n",
    "}\n",
    "\n",
    "rf_home_model, rf_home_pred = run_regression_grid_search(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    rf_reg_param_grid,\n",
    "    model_name=\"RandomForestRegressor\",\n",
    "    y_train=y_reg_home_train,\n",
    "    y_test=y_reg_home_test,\n",
    "    target_label=\"Home Score\",\n",
    "    results_dict=regression_results_home,\n",
    ")\n",
    "\n",
    "# 7.4 GradientBoostingRegressor – Home score\n",
    "gb_reg_param_grid = {\n",
    "    \"model__n_estimators\": [100, 200],\n",
    "    \"model__learning_rate\": [0.05, 0.1],\n",
    "    \"model__max_depth\": [2, 3],\n",
    "}\n",
    "\n",
    "gb_home_model, gb_home_pred = run_regression_grid_search(\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    gb_reg_param_grid,\n",
    "    model_name=\"GradientBoostingRegressor\",\n",
    "    y_train=y_reg_home_train,\n",
    "    y_test=y_reg_home_test,\n",
    "    target_label=\"Home Score\",\n",
    "    results_dict=regression_results_home,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e0b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for AWAY score\n",
    "\n",
    "# Ridge – Away score\n",
    "ridge_away_model, ridge_away_pred = run_regression_grid_search(\n",
    "    Ridge(),\n",
    "    ridge_param_grid,\n",
    "    model_name=\"Ridge\",\n",
    "    y_train=y_reg_away_train,\n",
    "    y_test=y_reg_away_test,\n",
    "    target_label=\"Away Score\",\n",
    "    results_dict=regression_results_away,\n",
    ")\n",
    "\n",
    "# Lasso – Away score\n",
    "lasso_away_model, lasso_away_pred = run_regression_grid_search(\n",
    "    Lasso(max_iter=10000),\n",
    "    lasso_param_grid,\n",
    "    model_name=\"Lasso\",\n",
    "    y_train=y_reg_away_train,\n",
    "    y_test=y_reg_away_test,\n",
    "    target_label=\"Away Score\",\n",
    "    results_dict=regression_results_away,\n",
    ")\n",
    "\n",
    "# RandomForestRegressor – Away score\n",
    "rf_away_model, rf_away_pred = run_regression_grid_search(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    rf_reg_param_grid,\n",
    "    model_name=\"RandomForestRegressor\",\n",
    "    y_train=y_reg_away_train,\n",
    "    y_test=y_reg_away_test,\n",
    "    target_label=\"Away Score\",\n",
    "    results_dict=regression_results_away,\n",
    ")\n",
    "\n",
    "# GradientBoostingRegressor – Away score\n",
    "gb_away_model, gb_away_pred = run_regression_grid_search(\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    gb_reg_param_grid,\n",
    "    model_name=\"GradientBoostingRegressor\",\n",
    "    y_train=y_reg_away_train,\n",
    "    y_test=y_reg_away_test,\n",
    "    target_label=\"Away Score\",\n",
    "    results_dict=regression_results_away,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35c9f2e",
   "metadata": {},
   "source": [
    "### 7.5 Regression Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05382342",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_reg_summary = pd.DataFrame(\n",
    "    {\n",
    "        name: {\"rmse\": res[\"rmse\"], \"r2\": res[\"r2\"]}\n",
    "        for name, res in regression_results_home.items()\n",
    "    }\n",
    ").T\n",
    "\n",
    "away_reg_summary = pd.DataFrame(\n",
    "    {\n",
    "        name: {\"rmse\": res[\"rmse\"], \"r2\": res[\"r2\"]}\n",
    "        for name, res in regression_results_away.items()\n",
    "    }\n",
    ").T\n",
    "\n",
    "print(\"Home score regression summary:\")\n",
    "display(home_reg_summary.sort_values(\"rmse\"))\n",
    "\n",
    "print(\"\\nAway score regression summary:\")\n",
    "display(away_reg_summary.sort_values(\"rmse\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f994ab",
   "metadata": {},
   "source": [
    "## 8. Visualization\n",
    "\n",
    "### 8.1 Predicted vs Actual Score Scatter Plots\n",
    "\n",
    "We use the **best-performing regression models** for home and away scores and visualize predicted vs actual values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edac0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predicted_vs_actual(y_true, y_pred, title):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.scatter(y_true, y_pred, alpha=0.6)\n",
    "    min_val = min(y_true.min(), y_pred.min())\n",
    "    max_val = max(y_true.max(), y_pred.max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val])\n",
    "    ax.set_xlabel(\"Actual\")\n",
    "    ax.set_ylabel(\"Predicted\")\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Choose the model with lowest RMSE for home and away\n",
    "best_home_model_name = min(regression_results_home, key=lambda k: regression_results_home[k][\"rmse\"])\n",
    "best_away_model_name = min(regression_results_away, key=lambda k: regression_results_away[k][\"rmse\"])\n",
    "\n",
    "best_home_pred = regression_results_home[best_home_model_name][\"y_pred\"]\n",
    "best_away_pred = regression_results_away[best_away_model_name][\"y_pred\"]\n",
    "\n",
    "print(\"Best home score model:\", best_home_model_name)\n",
    "print(\"Best away score model:\", best_away_model_name)\n",
    "\n",
    "plot_predicted_vs_actual(y_reg_home_test, best_home_pred, f\"Home Score – Predicted vs Actual ({best_home_model_name})\")\n",
    "plot_predicted_vs_actual(y_reg_away_test, best_away_pred, f\"Away Score – Predicted vs Actual ({best_away_model_name})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e06c40",
   "metadata": {},
   "source": [
    "### 8.2 Outcome Prediction Accuracy by Score Margin\n",
    "\n",
    "We can also examine how often the **predicted outcome** (from the best classification model) is correct\n",
    "as a function of the **true goal difference** (score margin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a8ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick best classification model by accuracy\n",
    "best_cls_model_name = max(classification_results, key=lambda k: classification_results[k][\"accuracy\"])\n",
    "best_cls_pred = classification_results[best_cls_model_name][\"y_pred\"]\n",
    "\n",
    "print(\"Best classification model:\", best_cls_model_name)\n",
    "\n",
    "# Compute true score margin (home - away) and absolute margin\n",
    "true_home = y_reg_home_test.reset_index(drop=True)\n",
    "true_away = y_reg_away_test.reset_index(drop=True)\n",
    "true_margin = true_home - true_away\n",
    "abs_margin = true_margin.abs()\n",
    "\n",
    "# Accuracy per margin bin\n",
    "bins = [0, 1, 2, 3, 5, np.inf]\n",
    "labels = [\"0\", \"1\", \"2\", \"3-4\", \"5+\"]\n",
    "margin_bins = pd.cut(abs_margin, bins=bins, labels=labels, right=False)\n",
    "\n",
    "correct = (best_cls_pred == y_cls_test.reset_index(drop=True)).astype(int)\n",
    "accuracy_by_margin = correct.groupby(margin_bins).mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.bar(accuracy_by_margin.index.astype(str), accuracy_by_margin.values)\n",
    "ax.set_xlabel(\"Absolute Goal Difference (True)\")\n",
    "ax.set_ylabel(\"Outcome Prediction Accuracy\")\n",
    "ax.set_title(\"Outcome Prediction Accuracy by Score Margin\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "accuracy_by_margin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db4cc7b",
   "metadata": {},
   "source": [
    "## 9. Conclusion & Next Steps\n",
    "\n",
    "In this notebook we:\n",
    "\n",
    "1. Loaded and concatenated multiple Premier League seasons (2019/2020–2021/2022).  \n",
    "2. Preprocessed the data with imputation, scaling, and one-hot encoding.  \n",
    "3. Trained and tuned **classification models** (SVM, Random Forest, Logistic Regression) to predict match outcomes.  \n",
    "4. Trained and tuned **regression models** (Ridge, Lasso, RandomForestRegressor, GradientBoostingRegressor) to predict final scores.  \n",
    "5. Evaluated models using appropriate metrics:  \n",
    "   - **Classification:** Accuracy, Precision, Recall, F1-score  \n",
    "   - **Regression:** RMSE, R²  \n",
    "6. Visualized confusion matrices, predicted vs actual scores, and outcome accuracy by score margin.\n",
    "\n",
    "**Possible extensions:**\n",
    "\n",
    "- Incorporate more advanced features (form, xG, home/away streaks, betting odds).  \n",
    "- Use time-aware validation (e.g., train on earlier seasons, test on later).  \n",
    "- Try more advanced models (XGBoost, LightGBM, neural networks).  \n",
    "- Calibrate predicted probabilities for betting strategies.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
