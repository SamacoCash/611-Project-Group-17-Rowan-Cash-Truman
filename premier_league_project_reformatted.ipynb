{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f570fe",
   "metadata": {},
   "source": [
    "\n",
    "# Premier League Match Prediction Project  \n",
    "### **Task A — Regression (Predicting Final Scores)**  \n",
    "### **Task B — Classification (Predicting Match Outcome)**\n",
    "\n",
    "This notebook follows the updated workflow:\n",
    "\n",
    "**STEP 1 — Load & Merge Dataset**  \n",
    "**STEP 2 — Feature Engineering**  \n",
    "**STEP 3 — Split Dataset into X and y**  \n",
    "- Regression: `X_reg`, `y_reg_home`, `y_reg_away`  \n",
    "- Classification: `X_clf`, `y_clf`  \n",
    "\n",
    "**Task A — Regression (Predicting Final Scores)**  \n",
    "**Task B — Classification (Predicting Match Outcome)**  \n",
    "\n",
    "**STEP 4 — Split into Train/Test**  \n",
    "**STEP 5 — Preprocessing Pipelines**  \n",
    "**STEP 6 — Train Each Pipeline SEPARATELY**  \n",
    "**STEP 7 — Evaluate Models**  \n",
    "**STEP 9 — Compare Model Performance**  \n",
    "**STEP 10 — Write Analysis + Conclusion**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b590e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Classification Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Regression Models\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,\n",
    "    mean_squared_error, r2_score\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5a926b",
   "metadata": {},
   "source": [
    "\n",
    "# **STEP 1 — Load & Merge Dataset**\n",
    "Update dataset paths as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb5f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Update dataset paths\n",
    "path_2019 = \"data/epl_2019_2020.csv\"\n",
    "path_2020 = \"data/epl_2020_2021.csv\"\n",
    "path_2021 = \"data/epl_2021_2022.csv\"\n",
    "\n",
    "df_19 = pd.read_csv(path_2019)\n",
    "df_20 = pd.read_csv(path_2020)\n",
    "df_21 = pd.read_csv(path_2021)\n",
    "\n",
    "df = pd.concat([df_19, df_20, df_21], ignore_index=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8438d5f",
   "metadata": {},
   "source": [
    "\n",
    "# **STEP 2 — Feature Engineering**\n",
    "Define classification + regression targets, map textual outcomes to numeric classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581413a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "home_team_col = \"HomeTeam\"\n",
    "away_team_col = \"AwayTeam\"\n",
    "home_goals_col = \"FTHG\"\n",
    "away_goals_col = \"FTAG\"\n",
    "result_col = \"FTR\"  # 'H','A','D'\n",
    "\n",
    "result_mapping = {\"H\": 0, \"A\": 1, \"D\": 2}\n",
    "df[\"outcome\"] = df[result_col].map(result_mapping)\n",
    "\n",
    "df[\"home_score\"] = df[home_goals_col]\n",
    "df[\"away_score\"] = df[away_goals_col]\n",
    "\n",
    "categorical_features = [home_team_col, away_team_col]\n",
    "numeric_features = [\n",
    "    col for col in df.columns\n",
    "    if col not in categorical_features + [result_col, \"outcome\", \"home_score\", \"away_score\"]\n",
    "    and pd.api.types.is_numeric_dtype(df[col])\n",
    "]\n",
    "\n",
    "features = categorical_features + numeric_features\n",
    "\n",
    "print(\"Features used:\", features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8005898",
   "metadata": {},
   "source": [
    "\n",
    "# **STEP 3 — Split Dataset into X and y**  \n",
    "## Task A — Regression  \n",
    "## Task B — Classification  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9ff763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_reg = df[features]\n",
    "y_reg_home = df[\"home_score\"]\n",
    "y_reg_away = df[\"away_score\"]\n",
    "\n",
    "X_clf = df[features]\n",
    "y_clf = df[\"outcome\"]\n",
    "\n",
    "X_reg.shape, X_clf.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f83d08",
   "metadata": {},
   "source": [
    "\n",
    "# **STEP 4 — Split into Train/Test**\n",
    "80-20 split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e081af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_reg_train, X_reg_test, y_home_train, y_home_test, y_away_train, y_away_test = train_test_split(\n",
    "    X_reg, y_reg_home, y_reg_away, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_clf_train, X_clf_test, y_clf_train, y_clf_test = train_test_split(\n",
    "    X_clf, y_clf, test_size=0.2, random_state=42, stratify=y_clf\n",
    ")\n",
    "\n",
    "X_reg_train.shape, X_clf_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d12f86",
   "metadata": {},
   "source": [
    "\n",
    "# **STEP 5 — Preprocessing Pipelines**\n",
    "Separate categorical and numeric pipelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a85502",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "])\n",
    "preprocessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948771a1",
   "metadata": {},
   "source": [
    "\n",
    "# **Task A — Regression (Predicting Final Scores)**  \n",
    "# **STEP 6A — Train Regression Pipelines (SEPARATELY)**\n",
    "Models:\n",
    "- Ridge  \n",
    "- Lasso  \n",
    "- RandomForestRegressor  \n",
    "- GradientBoostingRegressor  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce53d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_regression(model, params, y_train, y_test):\n",
    "    pipe = Pipeline([(\"preprocess\", preprocessor), (\"model\", model)])\n",
    "    \n",
    "    grid = GridSearchCV(pipe, params, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "    grid.fit(X_reg_train, y_train)\n",
    "    \n",
    "    y_pred = grid.predict(X_reg_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return grid.best_params_, rmse, r2, y_pred\n",
    "\n",
    "reg_results_home = {}\n",
    "reg_results_away = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4f84bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ridge_params = {\"model__alpha\": [0.1, 1, 10]}\n",
    "lasso_params = {\"model__alpha\": [0.001, 0.01, 0.1, 1]}\n",
    "rf_params = {\"model__n_estimators\": [100, 200], \"model__max_depth\": [None, 10, 20]}\n",
    "gb_params = {\n",
    "    \"model__n_estimators\": [100, 200],\n",
    "    \"model__learning_rate\": [0.05, 0.1],\n",
    "    \"model__max_depth\": [2, 3],\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"Ridge\": (Ridge(), ridge_params),\n",
    "    \"Lasso\": (Lasso(max_iter=10000), lasso_params),\n",
    "    \"RandomForestRegressor\": (RandomForestRegressor(), rf_params),\n",
    "    \"GradientBoostingRegressor\": (GradientBoostingRegressor(), gb_params)\n",
    "}\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    best_params, rmse, r2, pred = run_regression(model, params, y_home_train, y_home_test)\n",
    "    reg_results_home[name] = {\"params\": best_params, \"rmse\": rmse, \"r2\": r2}\n",
    "    \n",
    "    best_params, rmse, r2, pred = run_regression(model, params, y_away_train, y_away_test)\n",
    "    reg_results_away[name] = {\"params\": best_params, \"rmse\": rmse, \"r2\": r2}\n",
    "\n",
    "reg_results_home, reg_results_away\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd62eef2",
   "metadata": {},
   "source": [
    "\n",
    "# **Task B — Classification (Predicting Match Outcome)**  \n",
    "# **STEP 6B — Train Classification Models (SEPARATELY)**\n",
    "Models:\n",
    "- SVM  \n",
    "- Random Forest  \n",
    "- Logistic Regression  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9dfc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_classification(model, params):\n",
    "    pipe = Pipeline([(\"preprocess\", preprocessor), (\"model\", model)])\n",
    "    \n",
    "    grid = GridSearchCV(pipe, params, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid.fit(X_clf_train, y_clf_train)\n",
    "    \n",
    "    y_pred = grid.predict(X_clf_test)\n",
    "    acc = accuracy_score(y_clf_test, y_pred)\n",
    "    f1 = f1_score(y_clf_test, y_pred, average=\"weighted\")\n",
    "    return grid.best_params_, acc, f1, y_pred\n",
    "\n",
    "clf_results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95d9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svm_params = {\"model__kernel\": [\"rbf\", \"linear\"], \"model__C\": [0.1,1,10], \"model__gamma\": [\"scale\",\"auto\"]}\n",
    "rf_params = {\"model__n_estimators\": [100,200], \"model__max_depth\": [None,10,20]}\n",
    "logreg_params = {\"model__penalty\": [\"l1\",\"l2\"], \"model__C\": [0.1,1,10], \"model__solver\":[\"liblinear\"]}\n",
    "\n",
    "class_models = {\n",
    "    \"SVM\": (SVC(probability=True), svm_params),\n",
    "    \"RandomForestClassifier\": (RandomForestClassifier(), rf_params),\n",
    "    \"LogisticRegression\": (LogisticRegression(max_iter=1000), logreg_params)\n",
    "}\n",
    "\n",
    "for name, (model, params) in class_models.items():\n",
    "    clf_results[name] = run_classification(model, params)\n",
    "\n",
    "clf_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9903c482",
   "metadata": {},
   "source": [
    "\n",
    "# **STEP 7 — Evaluate Models**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3082ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame(reg_results_home)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2917881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame(reg_results_away)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e5e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame({\n",
    "    name: {\"Accuracy\": res[1], \"F1-score\": res[2]}\n",
    "    for name, res in clf_results.items()\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebc989e",
   "metadata": {},
   "source": [
    "\n",
    "# **STEP 10 — Analysis + Conclusion**\n",
    "\n",
    "Write your analysis here:\n",
    "- Which regression model performed the best?  \n",
    "- Which classification algorithm performed the best?  \n",
    "- Was the dataset balanced?  \n",
    "- Which features were most important?  \n",
    "- What improvements could be made in the next iteration?  \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
